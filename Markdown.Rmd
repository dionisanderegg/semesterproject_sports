---
title: "Markdown"
author: "Alissa Tophinke, Dionis Anderegg"
date: "27 Mai 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

#1 Data Preparation 
## 1.1 Load packages

load Packages :
```{r, message = FALSE}
library(rgdal) 
library(sf)
library(tidyverse)
library(lubridate)
library(zoo)
library(purrr)
library(base)

if(!requireNamespace("remotes")) {
    install.packages("remotes")
}
remotes::install_github("grimbough/FITfileR")

library(FITfileR)
library(gdata)
library(plotly)

#Packages for DEM import and handling
library(raster)
library(tiff)

```

## 1.2 Import data

Import all files with extension .fit from the R project folder and merge them into a single Data.frame. Delete all other Data.frames so that only the entire DF is in the workspace. Various calculations have to be done only once (timelag, distance etc.).

```{r message=TRUE, warning=FALSE}

# Files of every ahtlete must be labelled with _a1, _a2 or a_3 before the .fit extension.
#  Get all the files per athlete
myfiles_a1 <- list.files(".",pattern = "*a1.fit")
myfiles_a2 <- list.files(".",pattern = "*a2.fit")
myfiles_a3 <- list.files(".",pattern = "*a3.fit")

# Import files from athlete 1 temporary
for (i in 1:length(myfiles_a1)) {
  varName <- paste0("temp_a1", i, ".fit")
  assign(varName, as.data.frame(records(readFitFile(myfiles_a1[i]))))
}

# Bind row for athlete 1 temporary, label as athelte 1
a1 <- mget(ls(pattern="temp_a1")) %>%
              bind_rows() %>%
  mutate(athlete = 1)

# Import files from athlete 2 temporary
for (i in 1:length(myfiles_a2)) {
  varName <- paste0("temp_a2", i, ".fit")
  assign(varName, as.data.frame(records(readFitFile(myfiles_a2[i]))))
}

# Bind rows from athlete 2 temporary, label as athelte 2
a2 <- mget(ls(pattern="temp_a2")) %>%
              bind_rows() %>%
  mutate(athlete = 2)

# Import files from athlete 3 temporary
for (i in 1:length(myfiles_a3)) {
  varName <- paste0("temp_a3", i, ".fit")
  assign(varName, as.data.frame(records(readFitFile(myfiles_a3[i]))))
}

# Bind rows from athlete 2 temporary, label as athelte 3
a3 <- mget(ls(pattern="temp_a3")) %>%
              bind_rows() %>%
  mutate(athlete = 3)

# Bind files from all athletes using rowbind.
full <- bind_rows(a1, a2, a3)

keep(full, sure = TRUE)

#check full
head(full)
```


## 1.3 compare sport watch data with calculated values 

Calculate speed and timelags. Activities must be able to be grouped. This is done via the "activity_ID", which segments the data frame into individual tracks.
For the distance between two GPS fixes a SF object must be created and converted to the format CH1903+ LV95. From this the distance can be calculated.

### 1.3.1 calculate timelag and individual activity_ID for each track

```{r}
# Calculate timelag
full$timelag <- as.integer(difftime(full$timestamp, lag(full$timestamp)))
# activity_ID (new ID if timelag > 1 hour)
full$activity_conter <- ifelse(abs(full$timelag) > 3600, TRUE, FALSE) 
full$activity_conter[1] <- TRUE  # ID 1 = TRUE, as this is activity one
full$activity_ID <- cumsum(full$activity_conter == TRUE)  # create acitiviy_ID based on counter

```


### 1.3.2 calculate speed / add rollmean function
```{r}
# speed from tracker in km/h
full$enhanced_speed_kmh <- full$enhanced_speed *3.6

# smooth speed and heart rate by rollmenans

full <- full %>%
  group_by(activity_ID, athlete) %>%
  mutate(
    enhanced_speed_00 = enhanced_speed_kmh,
    enhanced_speed_02 = rollmean(enhanced_speed_kmh, k = 10, fill = NA, allign = "left"),
    enhanced_speed_05 = rollmean(enhanced_speed_kmh, k = 10, fill = NA, allign = "left"),
    enhanced_speed_10 = rollmean(enhanced_speed_kmh, k = 10, fill = NA, allign = "left"),
    enhanced_speed_30 = rollmean(enhanced_speed_kmh, k = 30, fill = NA, allign = "left"),
    enhanced_speed_60 = rollmean(enhanced_speed_kmh, k = 60, fill = NA, allign = "left")
  )

full <- full %>%
  group_by(activity_ID) %>%
  mutate(Track_Distance = max(distance)) %>%
  ungroup()

full %>%
  gather(window, speed, enhanced_speed_00 : enhanced_speed_60) %>%
  ggplot(aes(window, speed)) +
  geom_violin() +
  facet_wrap(~as.Date(timestamp))+
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "\nsize of the moving window", y = "speed in km/h\n")

full %>%
  filter(Track_Distance > 10000) %>%
  gather(window, speed, enhanced_speed_00 : enhanced_speed_60) %>%
  ggplot(aes(window, speed)) +
  geom_violin() +
  facet_wrap(~as.Date(timestamp))+
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "\nsize of the moving window", y = "speed in km/h\n")

full %>%
  filter(Track_Distance < 10000) %>%
  gather(window, speed, enhanced_speed_00 : enhanced_speed_60) %>%
  ggplot(aes(window, speed)) +
  geom_violin() +
  facet_wrap(~as.Date(timestamp))+
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "\nsize of the moving window", y = "speed in km/h\n")


full_smoothed_speed <- full %>%
  dplyr::select(athlete, activity_ID, enhanced_speed_kmh : enhanced_speed_60) %>%
  gather(window, speed, enhanced_speed_00 : enhanced_speed_60) %>%
  group_by(window, activity_ID) %>%
  summarise(mean = mean(speed, na.rm = TRUE),
            sd = sd(speed, na.rm = TRUE),
            var = var(speed, na.rm = TRUE))
full_smoothed_speed

ggplot(full_smoothed_speed, aes(window, mean)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean -var, ymax = mean+ var)) +
  facet_wrap(~activity_ID) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(x = "\n size of the moving window", y = "mean speed and variance per track\n")

#generate one random track in order to check
random_track <-sample(full$activity_ID, 1)

# How "k-value" affects the variety in speed:
full %>%
  filter(activity_ID == random_track) %>%
  gather(smoother, speed, 
         enhanced_speed_kmh, enhanced_speed_kmh, enhanced_speed_02 : enhanced_speed_60) %>%
  ggplot(aes(timestamp, speed, col = smoother)) +
  geom_line() +
  theme_bw()
ggplotly()


#calculate speed 

full_sf <- full_sf %>%
  group_by(activity_ID) %>%
  mutate(speed_calculated = steplength/timelag, 
         speed_calculated_kmh = 3.6*(steplength/timelag)
  )

#compare calculated speed with speed from sport watch (speed_enhanced)



compare_speed <- full_sf %>%
  filter(activity_ID == random_tracks) %>%
  ggplot() +
  geom_point(aes(timestamp, enhanced_speed_kmh, col = "measurement")) +
  #geom_point(aes(timestamp, speed_calculated_kmh, col = "calculated speed")) + #das kann nicht sein
  geom_point(aes(timestamp, enhanced_speed_05, col = "rolling_window, k=5")) +
  geom_point(aes(timestamp, enhanced_speed_10, col = "rolling_window, k=10")) +
  
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(~activity_ID, scales = "free") +
  labs(x = "\n time", y = "speed in km per h\n")

compare_speed

ggplotly(compare_speed)



```

###1.3.3 calculate Euclidean distance

```{r}

# Create sf and convert to CH1903+ LV95 to calculate the euculidian distance
full_sf <- st_as_sf(full, coords = c("position_long", "position_lat"),
         crs = 4326)
full_sf <- st_transform(full_sf, crs = 2056)

options(digits = 3)

# get x and y coordinates from sf geometry
full_sf$x <- st_coordinates(full_sf$geometry)[,1]
full_sf$y <- st_coordinates(full_sf$geometry)[,2]

# calculate Euclidian step length and speed
full_sf <- full_sf %>%
  group_by(activity_ID) %>%
  mutate(
    steplength = sqrt((x - lead(x))^2 + (y - lead(y))^2),
    steplenght_sum = cumsum(replace_na(steplength,0)),
    hightdiff = lead(enhanced_altitude) - enhanced_altitude,
    hightdiff_up = ifelse(hightdiff > 0, hightdiff, 0),
    hightdiff_down = ifelse(hightdiff < 0, hightdiff, 0), 
    
  )

#compare distance and steplength_sum

#generate random tracks to check
random_tracks <-sample(full_sf$activity_ID, 6)

compare_distance <- full_sf %>%
  filter(activity_ID == random_tracks) %>%
  ggplot() +
  geom_point(aes(timestamp, distance, col = "measurement", alpha=0.1)) +
  geom_point(aes(timestamp, steplenght_sum, col = "euclidian distance", alpha=0.1)) +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(~activity_ID, scales = "free") +
  labs(x = "\n time", y = "distance in meters\n")

compare_distance
ggplotly(compare_distance)
```


From the plots it can be shown that the distance (and speed) from the .fit file are very close to the calculated distance / speed values.

--> Continue with the data from the .fit file?



## 1.4 Remove “static points”

Define threshold: choose a threshold between stops and moves --> depending on data and question!


```{r}

#Remove “static points”

#Define threshold 

#plot trajectories with behavior pattern (static/moving) for Athlete 01 
#a) check data: histogram for speed for different tracks 

speed_mean <- mean(full_sf$enhanced_speed_05, na.rm=TRUE)

full_sf %>% 
  ggplot()+
  geom_histogram(aes(enhanced_speed_05))+
  geom_vline(aes(xintercept=speed_mean),linetype="dashed", color="blue")+
  geom_vline(aes(xintercept=3),linetype="dashed", color="red")+
  geom_text(x=3, y=-30, label="Threshold", color="red")+#set threshold = 3 from visual context
  geom_text(x=9.92, y=-30, label="mean", color="blue")


##all points which are < than the threshold value of 3m/s of enhanced_speed_5 are defined as static (moving)

tracks <- full_sf %>% 
  ungroup() %>%
  mutate(static = enhanced_speed_05 < 3)

#create a new data.frame with filtered 
tracks_filter <- tracks %>%
  filter(!static)

```



## 1.4 evaluate altitude with DEM => After creating full_sf!

```{r}
##  digital elevation model to verify altitude for each GPS location
#    we only import the necesary data now!

# Create a Dataframe containing all position (floor-rounded to 1km) as information source for required DHM-rasters
DHM_rasters <- data.frame(
  x = floor(full_sf$x / 1000),
  y = floor(full_sf$y / 1000)
)
# There are NA's when GPS-Position wasn't found (Activity_ID = 19) => Exclude them!
DHM_rasters <- filter(DHM_rasters, x > 0)

# Only keep the unique combinations for rounded x and y
DHM_rasters <- unique(DHM_rasters[c("x", "y")])

# Create the Download-Links of the tiff-files from Swisstopo: 
#  Sometimes data is from 2020, sometimes from 2019. Links aren't the same. So every combination has to be
#  produced for 2019 data and 2020 data.
DHM_URL <- c(
  paste("https://data.geo.admin.ch/ch.swisstopo.swissalti3d/swissalti3d_2019_", DHM_rasters$x, 
        "-", DHM_rasters$y, "/swissalti3d_2019_", DHM_rasters$x, "-", DHM_rasters$y, 
        "_2_2056_5728.tif", sep = ""),
  paste("https://data.geo.admin.ch/ch.swisstopo.swissalti3d/swissalti3d_2020_", DHM_rasters$x, 
        "-", DHM_rasters$y, "/swissalti3d_2020_", DHM_rasters$x, "-", DHM_rasters$y,
        "_2_2056_5728.tif", sep = ""))

# Create a data.frame for join later...
DHM_URL <- as.data.frame(DHM_URL)

# Read all available DEM-sources for whole Switzerland
DHM_full <- read_csv("DHM_CH.csv", col_names = "DHM_URL")

# Keep only DEM-sources, which are available in the source DHM_full (wohle Switzerland)
#  This ensures that the correct link (2019 or 2020) is chosen from DHM_full
DHM_required <- inner_join(DHM_URL, DHM_full)

# Now import all the required URL's as raster-list
r.list <- list()
for(i in 1:length(DHM_required$DHM_URL)){  
  r.list[[i]] <- raster(DHM_required$DHM_URL[i])  
} 

# Create a Rasterlayer from raster-list
m <- do.call(merge, r.list)

# Visialize imported data
plot(m)  # This should exactly cover the tracks used until now. 
# Reading of other tracks all over switzerland will result in the import of the required rasters above!! :)

# Extract elevation information from rasterlayer
data.matrix <- as.data.frame(rasterToPoints(m))

# Create identical names for join:
names(data.matrix)[names(data.matrix) == "x"] <- "x_round"
names(data.matrix)[names(data.matrix) == "y"] <- "y_round"

# create rounded x and y as join-key => every two meters, always odd values!
full_sf$x_round <- as.numeric(2 * round(full_sf$x/2) + 1)  
full_sf$y_round <- as.numeric(2 * round(full_sf$y/2) + 1)


# Join elevation 
full_sf_join <- left_join(full_sf, data.matrix, by = c("x_round", "y_round"))

# Calculate altitude difference between pressure measurement and DHM layer.
full_sf_join$altitude_diff <- full_sf_join$layer - full_sf_join$enhanced_altitude

# Test accuracy of elevation measurement
full_sf_join %>%
  gather(source, value, enhanced_altitude, layer) %>%
  filter(activity_ID < 10) %>%
  ggplot(aes(timestamp, value, col = source)) +
  geom_line() +
  facet_wrap(~activity_ID, scales = "free") +
  theme_bw()+
  labs(x = "\ntimestamp hh:mm", y = "altitude measurement m a.s.l.\n")+
  theme(legend.position = "bottom")

full_sf_join %>%
  filter(activity_ID < 10) %>%
  ggplot(aes(timestamp, altitude_diff)) +
  geom_line() +
  facet_wrap(~activity_ID, scales = "free") +
  theme_bw() +
  labs(x = "\ntimestamp hh:mm", y = "altitude difference (DEM - Tracker) in m\n")

```

# 2 RESEARCH QUESTION 1 -Explorative data analysis 

```{r}

# How altitude differences up affect speeds
full_sf %>%
  filter(activity_ID == 2) %>%
  ggplot(aes(timestamp, enhanced_speed_15)) +
  geom_line()+
  geom_line(aes(y = rollmean(hightdiff_up, k = 15, fill = NA, allign = "left")*10), col = "green3") +
  scale_y_continuous(
    "speed\n", 
    sec.axis = sec_axis(~ . * 0.1, name = "hight difference\n")
  )+
  theme_bw()

ggplotly()

# How altitude differences down affect speeds
full_sf %>%
  filter(activity_ID == 2) %>%
  ggplot(aes(timestamp, enhanced_speed_15)) +
  geom_line()+
  geom_line(aes(y = rollmean(-hightdiff_down, k = 15, fill = NA, allign = "left")*10), col = "green4") +
  scale_y_continuous(
    "speed\n", 
    sec.axis = sec_axis(~ . * 0.1, name = "hight difference\n")
  ) +
  theme_bw()
ggplotly()

```

Data analysis of individual tracks

## 2.1 General overview => Lenths, times, hightdifferences...

```{r}
full_long <- gather(full, type, value, enhanced_altitude:heart_rate, enhanced_speed_kmh)

library(shiny)
library(plotly)

#select plots which show graphically how the variables speed, altitude difference and heart rate behave.

#create function for generation of plots

plot_speed_altitude_heartrate_function <- function(track_ID){
  
  full_long %>%
  filter(activity_ID == track_ID) %>%
  ggplot(aes(timestamp, value, col = type)) +
  geom_line()+
  geom_point() +
  facet_wrap(~type, scales = "free",ncol = 1) +
  theme_bw() +
  theme(legend.position = "none") +
  labs(x = "\nUhrzeit in hh:mm", y = "Wert\n")
  
}

#count number of tracks (unique activity ID)
number_of_tracks <- length(unique(full_sf_join$activity_ID))
number_of_tracks

all_plots_speed_altitude_heartrate <- list() #create empty array

#save plots in array "all_plots_speed_altitude_heartrate"
for (track_ID in 1:number_of_tracks) {
    all_plots_speed_altitude_heartrate[[track_ID]]<-plot_speed_altitude_heartrate_function(track_ID)
  }
#create userinterface ui with shiny
ui <-shinyUI(fluidPage(selectInput("selectPlot", "Choose desired track", choices=1:number_of_tracks), plotlyOutput("plot")))

server <- shinyServer(function(input,output){      
  output$plot <- renderPlotly({
    all_plots_speed_altitude_heartrate[[strtoi(input$selectPlot)]]
  })
})

#get userinterface 
shinyApp(ui,server)


```

In der Tendenz lässt sich visuell eine Abnahme der Geschwindigkeit und eine Zunahme der Herzfrequenz mit einem Höhenanstieg erkennen. Ausserdem ist eine Pause von ca. 10 minuten duetlich am Geschwindigkeitdiagramm zu erkennen.

## 2.2 Possible outliers and evaluation area (scope)?

```{r}
#calculate duration of each track

full_short <- full %>% 
  group_by(activity_ID) %>% 
  mutate(duration_hour = as.numeric(difftime(max(timestamp), min(timestamp), units = "hours"))) 


full_short <- full_short %>% 
  group_by(activity_ID, duration_hour) %>% 
  summarize(value = mean(duration_hour)) %>%
  ungroup 

  ggplot(full_short)+
    geom_col(aes(x=(reorder(activity_ID,-duration_hour)),y=duration_hour))+
    coord_flip()+
    theme_bw()+
    ylim(0,3)+
    labs(title="duration of the tracks",
        x ="time in hour", y = "recorded track")
  
   
min(full_short$duration_hour)
max(full_short$duration_hour)

max(full_short$duration_hour)*1.1 #consider 10% deviation --> 3.06h 

  
#tracks duration beween 0.241 h and 2.78h for athlete 1  --> model prediction should not consider routes >3h

########calculate duration of each track without breaks

#take data.frame from chapter 5.1 (das mömer auwä no ommodle)

 
short_no_breaks <- tracks %>% 
  group_by(activity_ID) %>% 
  mutate(duration_hour_filtered = (for (i in static) {
 if(i = "FALSE"){
sum(timelag, na.rm = TRUE)
 }}))

short_no_breaks <- short_no_breaks %>% 
  group_by(activity_ID, duration_hour_filtered) %>% 
  summarize(value = mean(duration_hour_filtered)) %>%
  ungroup() 

  ggplot(short_no_breaks)+
    geom_col(aes(x=(reorder(activity_ID,-duration_hour_filtered)),y=duration_hour_filtered))+
    coord_flip()+
    theme_bw()+
    ylim(0,3)+
    labs(title= "duration of the tracks without breaks", x ="time in hour", y = "recorded track")

#try it in a different way:
storage <- numeric(length(unique(tracks$activity_ID)))


track_01 <-tracks %>% 
  select(activity_ID == 1 )

for (i in tracks$static) {
 storage[i]<-if(i == "FALSE"){
sum(tracks$timelag, na.rm = TRUE)}
}

#investigation for outliers

#function for outlier hat will return a boolean TRUE/FALSE if the value passed to it is an outlier: 
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}


full_short %>%
  mutate(outlier = ifelse(is_outlier(duration_hour), activity_ID, as.numeric(NA))) %>%
  ggplot(aes(x = activity_ID, y = duration_hour)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.1)+
  theme_bw()+
    labs(title="duration of the tracks",
        x ="time in hour", y = "different tracks athlete 01")
    

#track 1,8 and 19 has to be controlled for possible outliers

```

## 2.3  overview per track
```{r}
zf <- full_sf %>% #zf because of Zusammenfassung in german
  st_drop_geometry() %>%
  group_by(activity_ID) %>%
  summarise(
    date = date(timestamp[1]),
    distance = max(distance, na.rm = TRUE),
    time = as.numeric(difftime(max(timestamp), min(timestamp), units = "mins")),
    hightdiff_up = sum(hightdiff_up, na.rm = TRUE),
    hightdiff_down = sum(hightdiff_down, na.rm = TRUE),
    mean_pace = time / distance * 1000
    )
```


## 2.4 Map visualizations
Analyse some tracks and show them on map (interactive?)

Tracks auf Karten darstellen (verschiedene Packages und Methoden). Welche Packages eignen sich?

### 2.4.1 visualization without maps

ggplot:
```{r, message=FALSE}
# Visualisierung mit ggplot ohne Karte
library(tidyverse)
ggplot(filter(full, enhanced_speed_kmh > 4), aes (position_lat, position_long, col = enhanced_speed_kmh)) +
  geom_point() +
  facet_wrap(~activity_ID, scales = "free") +
  theme_bw()
```

Bei einigen Tracks scheint es noch ein Problem mit den Daten zu geben. = Siehe obiger Plot.

###2.4.2 visualization with leaflet

Leaflet ist interaktiv (m.E. sehr cool ;)) aber weniger einfach zu bearbeiten als ggplot oder ggmap (facets und einfärben von Datenpunkten etc.).
```{r, message = FALSE}
# Visualiseriung mit leaflet() => Interaktiv, schwer zu bearbeiten
library(leaflet)

# Track 1
m1 <- full %>%
  filter(activity_ID ==1) %>%
  select(position_long, position_lat) %>% 
  as.matrix() %>%
  leaflet(  ) %>%
  addTiles() %>%
  addPolylines( )
m1

# Track 2
m2 <- full %>%
  filter(activity_ID ==2) %>%
  select(position_long, position_lat) %>% 
  as.matrix() %>%
  leaflet(  ) %>%
  addTiles() %>%
  addPolylines( )
m2
```


ggmap() => Da die Karten importiert werden müssen nur für 3 Tracks gezeigt:
```{r, message = FALSE}
# Visualiserung mit ggmap
track1_3 <- full %>%
  filter(activity_ID < 4)

library(ggmap)

myLocation <- c(min(track1_3$position_long), min(track1_3$position_lat), 
                max(track1_3$position_long), max(track1_3$position_lat))  # Position definieren für Karten

myMap <- get_stamenmap(bbox=myLocation, maptype="terrain", crop=TRUE, zoom = 13)  # Kartenimport

ggmap(myMap) +
  geom_point(data = filter(track1_3, enhanced_speed_kmh > 3), 
             aes(position_long,position_lat, col = enhanced_speed_kmh)) +
  facet_wrap(~activity_ID) +
  labs(x = "\nLängengrad [°E]", y = "Breitengrad [°N]\n")
```



# 5 RESEARCH QUESTION 2 - Behaviour pattern

## 5.1 pausing - moving pattern

```{r}
#Remove “static points”

#Define threshold ---> described in chapter Data preparation

#plot trajectories with behavior pattern (static/moving) for Athlete 01 
tracks <- tracks %>%
  rename(
    "E" = "x",
    "N" = "y" ) 

athlete01 <-tracks%>% 
  ggplot(aes(E, N))  +
  geom_path() +
  geom_point(aes(colour = static)) +
  theme(legend.position = "right")+
  facet_wrap(~activity_ID)+
  ggtitle("Athlete_01")

ggplotly(athlete01)


#plot tracks with pausing/moving on maps




```

## 5.2 heart rate 

Can patterns in behavior be identified that are harmful to health? (Comparison of heart rate curve with recommended maximum heart rate).

--> everyone’s heart rate is different, Most athletes train at between 50 and 70 percent of their maximum heart rate.

```{r}


#max heart rate --literature athlete 1 
#date of athlete 1
birth_athelete1 <- as.Date('1983-10-20')
now <- Sys.time()

age_a1 <- time_length(difftime(now, birth_athelete1), "years")
age_a1

max_heart_rate_literature <- 220-age_a1
high_rate <- (max_heart_rate_literature*0.8)




tracks_heart <- tracks %>% 
  group_by(activity_ID) %>% 
    mutate(high = heart_rate > (0.8*(high_rate)), na.rm = TRUE)




#make plot with heart_rate normal (training) and high rate
ggplotly (tracks_heart%>%
  ggplot(aes(E, N, col=(high)))  +
  geom_path() +
  geom_point() +
  coord_fixed() +
  theme(legend.position = "right")+
  facet_wrap(.~activity_ID)+
  scale_color_manual(values=c("#E69F00", "red")))


```


# 6 RESEARCH QUESTION 3- model 

## 6.1 Establishment of a suitable model

Model basis => Segmeentation of all Tracks 
```{r}
full_sf_min <- full_sf %>%
  st_drop_geometry() %>%
  group_by("time" = cut(timestamp, "1 min")) %>%
  summarise(
    distance = sum(steplength, na.rm = TRUE),
    hightdiff_up = sum(hightdiff_up, na.rm = TRUE),
    hightdiff_down = sum(hightdiff_down, na.rm = TRUE),
    hightdiff_balance = hightdiff_up + hightdiff_down,
    time_eff = sum(timelag, na.rm = TRUE),
    mean_pace = time_eff / distance * 1000 / 60
  ) %>%
  mutate(vertical_direction = ifelse(hightdiff_balance > 2, "up",
                                      ifelse(hightdiff_balance < -2, "down",
                                             "horizontal")))

full_sf_min <- full_sf_min %>%
  filter(time_eff < 100, time_eff > 0, mean_pace < 25)
```


Multimodel Inference for zf.model

```{r}
if(!require(MuMIn)){install.packages("MuMIn")}
library(MuMIn)
library(gridExtra)

zf.model <- lm(zf$time ~ 0 + zf$distance + zf$hightdiff_up + zf$hightdiff_down, data=zf)
options(na.action="na.fail")
allmodels.zf <- dredge(zf.model)
allmodels.zf

importance(allmodels.zf)

avgmodel.zf<-model.avg(get.models(dredge(zf.model,rank="AICc"),subset=TRUE))
summary(avgmodel.zf)

# Komischerweise ist das "drittbeste Modell" einiges genauer als das beste Modell...
distance_param <- allmodels.zf$`zf$distance`[3]
up_param <- allmodels.zf$`zf$hightdiff_up`[3]
down_param <- allmodels.zf$`zf$hightdiff_down`[3]

zf$time_estimated <- zf$distance *distance_param + zf$hightdiff_up * up_param + zf$hightdiff_down * down_param

zf %>% 
  select(activity_ID, time_measured = time, time_estimated, distance, hightdiff_up, hightdiff_down) %>%
  gather(type, value, time_measured, time_estimated) %>%
  ggplot(aes(distance, value, col = type)) +
  geom_point() +
  geom_line() +
  geom_text(aes(y = max(zf$time) + 15, label = paste("Dist:", round(distance/1000,1), "km"))) +
  geom_text(aes(y = max(zf$time) + 10, label = paste("Aufw.:", round(hightdiff_up,0), "m"))) +
  geom_text(aes(y = max(zf$time) + 5, label = paste("Abw.:", -round(hightdiff_down,0), "m"))) +
  theme_bw() +
  labs(x = "\nAktivitäts-ID", y = "Zeitbedarf in min\n")

zf %>% 
  select(activity_ID, time_measured = time, time_estimated, distance, hightdiff_up, hightdiff_down) %>%
  gather(type, value, time_measured, time_estimated) %>%
  ggplot(aes(distance, value, col = type)) +
  geom_point() +
  geom_smooth()
```


Multimodel Inference for min.model

```{r}
min.model <- lm(time_eff/60 ~ 0 + distance + hightdiff_up + hightdiff_down, data=full_sf_min)
options(na.action="na.fail")
allmodels.min <- dredge(min.model)
allmodels.min   # model[1] makes more sence than zf.model!
# Interpretation: Per meter of Distance 0.00461 minutes, per meter up 0.035 minutes
#  per meter down 0.01 minutes (negative because hightdiff_down is negative!).

importance(allmodels.min)

avgmodel.min<-model.avg(get.models(dredge(min.model,rank="AICc"),subset=TRUE))
summary(avgmodel.min) # All predictors are highli significant!

# Komischerweise ist das "drittbeste Modell" einiges genauer als das beste Modell...
distance_param_min <- allmodels.min$distance[1]
up_param_min <- allmodels.min$hightdiff_up[1]
down_param_min <- allmodels.min$hightdiff_down[1]

zf$time_estimated_min <- zf$distance *distance_param_min + zf$hightdiff_up * up_param_min + zf$hightdiff_down * down_param_min

zf %>% 
  select(activity_ID, time_measured = time, time_estimated, time_estimated_min, distance, hightdiff_up, hightdiff_down) %>%
  gather(type, value, time_measured, time_estimated, time_estimated_min) %>%
  ggplot(aes(activity_ID, value, col = type)) +
  geom_point() +
  geom_line() +
  theme_bw() +
  labs(x = "\nAktivitäts-ID", y = "Zeitbedarf in min\n")

zf %>% 
  select(activity_ID, time_measured = time, time_estimated_min, distance, hightdiff_up, hightdiff_down) %>%
  gather(type, value, time_measured, time_estimated_min) %>%
  ggplot(aes(distance, value, col = type)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_bw()
# It seems that the model underestimates time requirement for long distances, and overestimates
#  for short distances => Exhaution!

# Show the pace-dependency of the hightdifference up
full_sf_min %>%
  filter(vertical_direction == "up") %>%
  ggplot(aes(hightdiff_up, mean_pace)) +
  geom_point() +
  geom_smooth(span = 1) +
  ylim(4.3,14.5) +
  theme_bw() +
  labs(x = "\nhightdifference up per minute of running time", y = "mean pace per minute of running time\n")

full_sf_min %>%
  filter(vertical_direction == "down") %>%
  ggplot(aes(-hightdiff_down, mean_pace)) +
  geom_point() +
  geom_smooth(span = 1) +
  ylim(4.4,11) +
  xlim(0,38) +
  theme_bw() +
  labs(x = "\nhightdifference down per minute of running time", y = "mean pace per minute of running time\n")

ggplot(full_sf_min, aes(mean_pace, hightdiff_down)) +
  geom_point()

```

## 6.2 validation of the model 


```{r}



```

