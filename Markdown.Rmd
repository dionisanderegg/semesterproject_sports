---
title: "Markdown"
author: "Alissa Tophinke, Dionis Anderegg"
date: "27 Mai 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

#1 Data Preparation 
## 1.1 Load packages

load Packages :
```{r, message = FALSE}
library(rgdal) 
library(sf)
library(tidyverse)
library(lubridate)
library(zoo)
library(purrr)
library(base)
library(ggpubr)

if(!requireNamespace("remotes")) {
    install.packages("remotes")
}
remotes::install_github("grimbough/FITfileR")

library(FITfileR)
library(gdata)
library(plotly)

#Packages for DEM import and handling
library(raster)
library(tiff)

```

## 1.2 Import data

Import all files with extension .fit from the R project folder and merge them into a single Data.frame. Delete all other Data.frames so that only the entire DF is in the workspace. Various calculations have to be done only once (timelag, distance etc.).

```{r message=TRUE, warning=FALSE}
############### Filter data fro one athlete only (andd)
# Files of every ahtlete must be labelled with _a1, _a2 or a_3 before the .fit extension.

#  Get all the files per athlete
myfiles_a1 <- list.files(".",pattern = "*a1.fit")
myfiles_a2 <- list.files(".",pattern = "*a2.fit")
myfiles_a3 <- list.files(".",pattern = "*a3.fit")

# Import files from athlete 1 temporary
for (i in 1:length(myfiles_a1)) {
  varName <- paste0("temp_a1", i, ".fit")
  assign(varName, as.data.frame(records(readFitFile(myfiles_a1[i]))))
}

# Bind row for athlete 1 temporary, label as athelte 1
a1 <- mget(ls(pattern="temp_a1")) %>%
              bind_rows() %>%
  mutate(athlete = 1)

# Import files from athlete 2 temporary
for (i in 1:length(myfiles_a2)) {
  varName <- paste0("temp_a2", i, ".fit")
  assign(varName, as.data.frame(records(readFitFile(myfiles_a2[i]))))
}

# Bind rows from athlete 2 temporary, label as athelte 2
a2 <- mget(ls(pattern="temp_a2")) %>%
              bind_rows() %>%
  mutate(athlete = 2)

# Import files from athlete 3 temporary
for (i in 1:length(myfiles_a3)) {
  varName <- paste0("temp_a3", i, ".fit")
  assign(varName, as.data.frame(records(readFitFile(myfiles_a3[i]))))
}

# Bind rows from athlete 2 temporary, label as athelte 3
a3 <- mget(ls(pattern="temp_a3")) %>%
              bind_rows() %>%
  mutate(athlete = 3)

# Bind files from all athletes using rowbind.
full <- bind_rows(a1, a2, a3)

keep(full, sure = TRUE)


# Filter the whole data according to athlete to be analysed: Pick an athlete!
Pick_Athlete <- 1

full <- full %>%
  filter(athlete == Pick_Athlete)

############# Filter here! User defines which athlete is considered (andd)

#check full
head(full)
```

## 1.3 compare sport watch data with calculated values 

Calculate speed and timelags. Activities must be able to be grouped. This is done via the "activity_ID", which segments the data frame into individual tracks.
For the distance between two GPS fixes a SF object must be created and converted to the format CH1903+ LV95. From this the distance can be calculated.

### 1.3.1 calculate timelag and individual activity_ID for each track

```{r}
# Calculate timelag
full$timelag <- as.integer(difftime(full$timestamp, lag(full$timestamp)))
# activity_ID (new ID if timelag > 1 hour)
full$activity_conter <- ifelse(abs(full$timelag) > 3600, TRUE, FALSE) 
full$activity_conter[1] <- TRUE  # ID 1 = TRUE, as this is activity one
full$activity_ID <- cumsum(full$activity_conter == TRUE)  # create acitiviy_ID based on counter

full <- full %>%
  dplyr::group_by(activity_ID) %>%
  mutate(timelag = as.integer(difftime(timestamp, lag(timestamp))))
summary(full$timelag)

# Group_by(acitvityID) => TImelag (andd)

```

###1.3.2 calculate Euclidean distance

```{r}

# Create sf and convert to CH1903+ LV95 to calculate the euculidian distance
full_sf <- st_as_sf(full, coords = c("position_long", "position_lat"),
         crs = 4326)
full_sf <- st_transform(full_sf, crs = 2056)

options(digits = 3)

# get x and y coordinates from sf geometry
full_sf$x <- st_coordinates(full_sf$geometry)[,1]
full_sf$y <- st_coordinates(full_sf$geometry)[,2]
```


```{r}
##  digital elevation model to verify altitude for each GPS location
#    we only import the necesary data now!

# Create a Dataframe containing all position (floor-rounded to 1km) as information source for required DHM-rasters
DHM_rasters <- data.frame(
  x = floor(full_sf$x / 1000),
  y = floor(full_sf$y / 1000)
)
# There are NA's when GPS-Position wasn't found (Activity_ID = 19) => Exclude them!
DHM_rasters <- filter(DHM_rasters, x > 0)

# Only keep the unique combinations for rounded x and y
DHM_rasters <- unique(DHM_rasters[c("x", "y")])

# Create the Download-Links of the tiff-files from Swisstopo: 
#  Sometimes data is from 2020, sometimes from 2019. Links aren't the same. So every combination has to be
#  produced for 2019 data and 2020 data.
DHM_URL <- c(
  paste("https://data.geo.admin.ch/ch.swisstopo.swissalti3d/swissalti3d_2019_", DHM_rasters$x, 
        "-", DHM_rasters$y, "/swissalti3d_2019_", DHM_rasters$x, "-", DHM_rasters$y, 
        "_2_2056_5728.tif", sep = ""),
  paste("https://data.geo.admin.ch/ch.swisstopo.swissalti3d/swissalti3d_2020_", DHM_rasters$x, 
        "-", DHM_rasters$y, "/swissalti3d_2020_", DHM_rasters$x, "-", DHM_rasters$y,
        "_2_2056_5728.tif", sep = ""))

# Create a data.frame for join later...
DHM_URL <- as.data.frame(DHM_URL)

# Read all available DEM-sources for whole Switzerland
DHM_full <- read_csv("DHM_CH.csv", col_names = "DHM_URL")

# Keep only DEM-sources, which are available in the source DHM_full (wohle Switzerland)
#  This ensures that the correct link (2019 or 2020) is chosen from DHM_full
DHM_required <- inner_join(DHM_URL, DHM_full)

# Now import all the required URL's as raster-list
r.list <- list()
for(i in 1:length(DHM_required$DHM_URL)){  
  r.list[[i]] <- raster(DHM_required$DHM_URL[i])  
} 

# Create a Rasterlayer from raster-list
m <- do.call(merge, r.list)

# Visialize imported data
plot(m)  # This should exactly cover the tracks used until now. 
# Reading of other tracks all over switzerland will result in the import of the required rasters above!! :)

# Extract elevation information from rasterlayer
data.matrix <- as.data.frame(rasterToPoints(m))

# Create identical names for join:
names(data.matrix)[names(data.matrix) == "x"] <- "x_round"
names(data.matrix)[names(data.matrix) == "y"] <- "y_round"

# create rounded x and y as join-key => every two meters, always odd values!
full_sf$x_round <- as.numeric(2 * round(full_sf$x/2) + 1)  
full_sf$y_round <- as.numeric(2 * round(full_sf$y/2) + 1)


# Join elevation 
full_sf <- left_join(full_sf, data.matrix, by = c("x_round", "y_round"))

#####  dplyr::rename  => change layer to altitude_DEM (andd)

# Calculate altitude difference between pressure measurement and DHM layer.
full_sf$altitude_diff <- full_sf$layer - full_sf$enhanced_altitude

# Test accuracy of elevation measurement
full_sf %>%
  gather(source, value, enhanced_altitude, layer) %>%
  filter(activity_ID < 10) %>%
  ggplot(aes(timestamp, value, col = source)) +
  geom_line() +
  facet_wrap(~activity_ID, scales = "free") +
  theme_bw()+
  labs(x = "\ntimestamp hh:mm", y = "altitude measurement m a.s.l.\n")+
  theme(legend.position = "bottom")

p.hightdiff <- full_sf %>%
  ggplot(aes(timestamp, altitude_diff)) +
  geom_line() +
  facet_wrap(~activity_ID, scales = "free") +
  theme_bw() +
  labs(x = "\ntimestamp hh:mm", y = "altitude difference (DEM - pressure measurement) in m\n")
p.hightdiff <- ggplotly(p.hightdiff)
p.hightdiff

htmlwidgets::saveWidget(as.widget(p.hightdiff), "plots_figures/p.hightdifference.html")
```

```{r}
# calculate Euclidian step length and speed
full_sf <- full_sf %>%
  group_by(activity_ID) %>%
  mutate(
    steplength = sqrt((x - lead(x))^2 + (y - lead(y))^2),
    steplenght_sum = cumsum(replace_na(steplength,0)),
    hightdiff = lead(layer) - layer, # laver is the elevation from the DEM!
    hightdiff_up = ifelse(hightdiff > 0, hightdiff, 0),
    hightdiff_down = ifelse(hightdiff < 0, hightdiff, 0)
  )

#compare distance and steplength_sum

#generate random tracks to check
random_tracks <-sample(full_sf$activity_ID, 6)

#### Distance (absolute or in percent) instead of comparison (tophial)

compare_distance <- full_sf %>%
  filter(activity_ID == random_tracks) %>%
  ggplot() +
  geom_point(aes(timestamp, distance, col = "measurement"), alpha = 0.1) +
  geom_point(aes(timestamp, steplenght_sum, col = "euclidian distance"), alpha = 0.1) +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(~activity_ID, scales = "free") +
  labs(x = "\n time", y = "distance in meters\n")

compare_distance
ggplotly(compare_distance)
```


### 1.3.3 calculate speed / add rollmean function
```{r}
# speed from tracker in km/h
full_sf$enhanced_speed_kmh <- full$enhanced_speed *3.6

# smooth speed and heart rate by rollmenans

full_sf <- full_sf %>%
  group_by(activity_ID, athlete) %>%
  mutate(
    enhanced_speed_00 = enhanced_speed_kmh,
    enhanced_speed_02 = rollmean(enhanced_speed_kmh, k = 2, fill = NA, allign = "left"),
    enhanced_speed_03 = rollmean(enhanced_speed_kmh, k = 3, fill = NA, allign = "left"),
    enhanced_speed_05 = rollmean(enhanced_speed_kmh, k = 5, fill = NA, allign = "left"),
    enhanced_speed_10 = rollmean(enhanced_speed_kmh, k = 10, fill = NA, allign = "left"),
    enhanced_speed_50 = rollmean(enhanced_speed_kmh, k = 50, fill = NA, allign = "left")
  )

full_sf <- full_sf %>%
  group_by(activity_ID) %>%
  mutate(Track_Distance = max(distance)) %>%
  ungroup()

######## Use this graph for report
full_sf %>%
  gather(window, speed, enhanced_speed_00 : enhanced_speed_50) %>%
  ggplot(aes(window, speed)) +
  geom_violin() +
  facet_wrap(~as.Date(timestamp))+
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "\nsize of the moving window", y = "speed in km/h\n")

#check moving windows for track distances > 10km
full_sf %>%
  filter(Track_Distance > 10000) %>%
  gather(window, speed, enhanced_speed_00 : enhanced_speed_50) %>%
  ggplot(aes(window, speed)) +
  geom_violin() +
  facet_wrap(~as.Date(timestamp))+
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "\nsize of the moving window", y = "speed in km/h\n")

#check moving windows for track distances < 10km
full_sf %>%
  filter(Track_Distance < 10000) %>%
  gather(window, speed, enhanced_speed_00 : enhanced_speed_50) %>%
  ggplot(aes(window, speed)) +
  geom_violin() +
  facet_wrap(~as.Date(timestamp))+
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "\nsize of the moving window", y = "speed in km/h\n")

#generate one random track in order to check (for athlete 1)
random_track <-sample(full$activity_ID, 1)

############## Use in Report!
# How "k-value" affects the variety in speed:
full_sf %>%
  filter(activity_ID == random_track) %>%
  gather(smoother, speed, enhanced_speed_00 : enhanced_speed_50) %>%
  ggplot(aes(timestamp, speed, col = smoother)) +
  geom_line() +
  theme_bw()
ggplotly()


#### USe k = 3 for further analysis

```


From the plots it can be shown that the distance (and speed) from the .fit file are very close to the calculated distance / speed values.

--> Continue with the data from the .fit file?



## 1.4 Remove “static points”

Define threshold: choose a threshold between stops and moves --> depending on data and question!


```{r}

#Remove “static points”

#Define threshold 

#plot trajectories with behavior pattern (static/moving) for Athlete 01 
#a) check data: histogram for speed for different tracks 

speed_mean <- mean(full_sf$enhanced_speed_03, na.rm=TRUE)

full_sf %>% 
  ggplot()+
  geom_histogram(aes(enhanced_speed_03), binwidth = 0.5)+
  geom_vline(aes(xintercept=speed_mean),linetype="dashed", color="blue")+
  geom_vline(aes(xintercept=3.25),linetype="dashed", color="red")+
  geom_text(x=3.25, y=-30, label="Threshold", color="red")+#set threshold = 3 from visual context
  geom_text(x=9.92, y=-30, label="mean", color="blue")

### Define as static when speed < 3.25 km/h


##all points which are < than the threshold value of 3m/s of enhanced_speed_kmh are defined as static (moving)
#### Save in full_sf instead of tracks
full_sf <- full_sf %>% 
  ungroup() %>%
  mutate(static = enhanced_speed_03 <= 3.25)
```



## 1.4 evaluate altitude with DEM => After creating full_sf!

```{r}
# copied to 1.3

```

# 2 RESEARCH QUESTION 1 -Explorative data analysis 

```{r}

# How altitude differences up affect speeds
diff_up <- full_sf %>%
  filter(activity_ID == 2) %>%
  ggplot(aes(timestamp, enhanced_speed_03)) +
  geom_line()+
  geom_line(aes(y = rollmean(hightdiff_up, k = 15, fill = NA, allign = "left")*10), col = "green3") +
  scale_y_continuous(
    "speed (black)\n", 
    sec.axis = sec_axis(~ . * 0.1, name = "hight difference (green)\n")
  )+
  theme_bw()

ggplotly()

# How altitude differences down affect speeds
diff_down <- full_sf %>%
  filter(activity_ID == 2) %>%
  ggplot(aes(timestamp, enhanced_speed_05)) +
  geom_line()+
  geom_line(aes(y = rollmean(-hightdiff_down, k = 15, fill = NA, allign = "left")*10), col = "green4") +
  scale_y_continuous(
    "speed (black)\n", 
    sec.axis = sec_axis(~ . * 0.1, name = "hight difference (green)\n")
  ) +
  theme_bw()
ggplotly()

figure_speed <- ggarrange(diff_down, diff_up,
                    labels = c("up", "down"),
                    ncol = 2, nrow = 1)
figure_speed
```

Data analysis of individual tracks

## 2.1 General overview => Lenths, times, hightdifferences...

```{r}
full_long <- gather(full_sf, type, value, layer, heart_rate, enhanced_speed_03)

library(shiny)
library(plotly)

#select plots which show graphically how the variables speed, altitude difference and heart rate behave.

#create function for generation of plots

plot_speed_altitude_heartrate_function <- function(track_ID){
  
  full_long %>%
  filter(activity_ID == track_ID) %>%
  ggplot(aes(timestamp, value, col = type)) +
  geom_line()+
  geom_point() +
  facet_wrap(~type, scales = "free",ncol = 1) +
  theme_bw() +
  theme(legend.position = "none") +
  labs(x = "\nUhrzeit in hh:mm", y = "Wert\n")
  
}

#count number of tracks (unique activity ID)
number_of_tracks <- length(unique(full_sf_join$activity_ID))
number_of_tracks

all_plots_speed_altitude_heartrate <- list() #create empty array

#save plots in array "all_plots_speed_altitude_heartrate"
for (track_ID in 1:number_of_tracks) {
    all_plots_speed_altitude_heartrate[[track_ID]]<-plot_speed_altitude_heartrate_function(track_ID)
  }
#create userinterface ui with shiny
ui <-shinyUI(fluidPage(selectInput("selectPlot", "Choose desired track", choices=1:number_of_tracks), plotlyOutput("plot")))

server <- shinyServer(function(input,output){      
  output$plot <- renderPlotly({
    all_plots_speed_altitude_heartrate[[strtoi(input$selectPlot)]]
  })
})

#get userinterface 
shinyApp(ui,server)


```

The trend visually shows a decrease in speed and an increase in heart rate with an increase in altitude. In addition, a pause of approx. 10 minutes can be seen duetly on the speed diagram.

## 2.2 Possible outliers and evaluation area (scope)?

```{r}
#calculate duration of each track and
#calculate duration of each track without breaks and
#calculate duration of breaks per track

full_sf_filtered <- full_sf %>% 
  group_by(activity_ID) %>% 
  mutate(duration_whole_track = as.numeric(difftime(max(timestamp), min(timestamp), units = "hours"))) %>% #in hours
  ungroup() %>% 
  group_by(activity_ID, static) %>% 
  filter(static == FALSE) %>% 
    mutate(duration_moving = sum(timelag, na.rm = TRUE) / 3600) %>% 
  ungroup() %>% 
  mutate(duration_breaks = (duration_whole_track - duration_moving), 
         duration_breaks_min = (duration_breaks*60))


full_short <- full_sf_filtered %>% 
  group_by(activity_ID) %>% 
  summarize(duration_track = mean(duration_whole_track), 
            duration_moving = mean(duration_moving), 
            duration_breaks = mean(duration_breaks), 
            duration_breaks_min= mean(duration_breaks_min)) %>%
  ungroup() 

  ggplot(full_short)+
    geom_col(aes(x=(reorder(activity_ID,-duration_moving)),y=duration_moving))+
    coord_flip()+
    theme_bw()+
    ylim(0,3)+
    labs(title="moving duration of the tracks",
        x ="tracks", y = "time in hours")
  
   
min(full_short$duration_moving)
max(full_short$duration_moving)

max(full_short$duration_moving)*1.1 #consider 10% deviation --> 3.05h 

  
#tracks duration beween 0.235 h and 2.77h for athlete 1  --> model prediction should not consider routes >3h


#investigation for outliers

#function for outlier hat will return a boolean TRUE/FALSE if the value passed to it is an outlier: 
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}


full_short %>%
  mutate(outlier = ifelse(is_outlier(duration_moving), activity_ID, as.numeric(NA))) %>%
  ggplot(aes(x = activity_ID, y = duration_moving)) +
    geom_boxplot() +
    geom_text(aes(x = 9.5, label = outlier), na.rm = TRUE, hjust = -0.2)+
  theme_bw()+
    labs(title="moving duration of the tracks",
        x ="", y = "time in hours\n") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

  

#track 1 has to be controlled for possible outliers

```

## 2.3  overview per track /summary
```{r}

#### Use values from full_short! (andd)
zf <- full_sf %>% #zf because of "Zusammenfassung" in german
  st_drop_geometry() %>%
  group_by(activity_ID) %>%
  summarise(
    date = date(timestamp[1]),
    distance = max(distance, na.rm = TRUE),
    time = as.numeric(difftime(max(timestamp), min(timestamp), units = "mins")),
    hightdiff_up = sum(hightdiff_up, na.rm = TRUE),
    hightdiff_down = sum(hightdiff_down, na.rm = TRUE),
    mean_pace = time / distance * 1000
    )
```


## 2.4 Map visualizations

Analyse some tracks and show them on map (interactive?)

Tracks auf Karten darstellen (verschiedene Packages und Methoden). Welche Packages eignen sich?

### 2.4.1 visualization without maps

ggplot:
```{r, message=FALSE}
#### Tidy this chapter (andd)
# Visualisierung mit ggplot ohne Karte
library(tidyverse)
ggplot(filter(full_sf, enhanced_speed_kmh > 4), aes (position_lat, position_long, col = enhanced_speed_kmh)) +
  geom_point() +
  facet_wrap(~activity_ID, scales = "free") +
  theme_bw()
```

Bei einigen Tracks scheint es noch ein Problem mit den Daten zu geben. = Siehe obiger Plot.

###2.4.2 visualization with leaflet

Leaflet ist interaktiv (m.E. sehr cool ;)) aber weniger einfach zu bearbeiten als ggplot oder ggmap (facets und einfärben von Datenpunkten etc.).
```{r, message = FALSE}
# Visualiseriung mit leaflet() => Interaktiv, schwer zu bearbeiten
library(leaflet)

# Track 1
m1 <- full %>%
  filter(activity_ID ==random_track) %>%
  dplyr::select(position_long, position_lat) %>% 
  as.matrix() %>%
  leaflet(  ) %>%
  addTiles() %>%
  addPolylines( )
m1
```
### 2.4.3 visualization with ggmap

ggmap() => Da die Karten importiert werden müssen nur für 3 Tracks gezeigt:
```{r, message = FALSE}
# Visualiserung mit ggmap
track1_3 <- full %>%
  filter(activity_ID < 4)

library(ggmap)

myLocation <- c(min(track1_3$position_long), min(track1_3$position_lat), 
                max(track1_3$position_long), max(track1_3$position_lat))  # Position definieren für Karten

myMap <- get_stamenmap(bbox=myLocation, maptype="terrain", crop=TRUE, zoom = 13)  # Kartenimport

ggmap(myMap) +
  geom_point(data = filter(track1_3, enhanced_speed_kmh > 3), 
             aes(position_long,position_lat, col = enhanced_speed_kmh)) +
  facet_wrap(~activity_ID) +
  labs(x = "\nLängengrad [°E]", y = "Breitengrad [°N]\n")
```




# 5 RESEARCH QUESTION 2 - Behaviour pattern

## 5.1 pausing - moving pattern

```{r}
#plot trajectories with behavior pattern (static/moving) for Athlete 01 
athlete01 <- full_sf%>% 
  ggplot(aes(x = x, y = y))  +
  geom_path() +
  geom_point(aes(colour = static)) +
  theme(legend.position = "right")+
  facet_wrap(~activity_ID)+
  ggtitle("Athlete_01")


ggplotly(athlete01)

#Breaks in relation to the runtime

ggplot(full_short, aes(x=duration_breaks, y=duration_moving)) + 
  geom_point() +
  geom_text(aes(label=activity_ID),hjust=0, vjust=0)+
  geom_smooth(method="lm", fill='lightblue', size=0.5, alpha=0.5) +
  theme(axis.text=element_text(size=12), axis.title=element_text(size=14,face="bold"))+
  labs(x = "\nduration of breaks [h]", y = "duration of moving [h]\n")
  
#unrealistic pausing hours!!?? 

#plot tracks with pausing/moving on maps

leaflet(athlete01) %>% 
    addTiles() %>% 
    addPolylines(lat = athlete01$E, lng = athlete01$N)


```

## 5.2 heart rate 

Can patterns in behavior be identified that are harmful to health? (Comparison of heart rate curve with recommended maximum heart rate).

--> everyone’s heart rate is different, Most athletes train at between 50 and 70 percent of their maximum heart rate.

According to Such and Meyer (2010) HFmax is calculated by 220 - age (for running) for men. 
Also women-specific rules of thumb such as HFmax = 206 - (age x 0.88) exist, but it will not be considered, as all athletes in this report are men
```{r}


#max heart rate --literature athlete 1 
#date of athlete 1
birth_athelete1 <- as.Date('1991-11-16')
now <- Sys.time()

age_a1 <- time_length(difftime(now, birth_athelete1), "years")
age_a1

max_heart_rate_literature <- 220-age_a1
high_rate <- (max_heart_rate_literature*0.86)


tracks_heart <- tracks %>% 
  group_by(activity_ID) %>% 
    mutate(high = heart_rate > (high_rate), na.rm = TRUE)


#make plot with heart_rate normal (training) and high rate
ggplotly (tracks_heart%>%
  ggplot(aes(E, N, col=(high)))  +
  geom_path() +
  geom_point() +
  coord_fixed() +
  theme(legend.position = "right")+
  facet_wrap(.~activity_ID)+
  scale_color_manual(values=c("#E69F00", "red")))


```


# 6 RESEARCH QUESTION 3- model 

## 6.1 Establishment of a suitable model

Model basis => Segmeentation of all Tracks 
```{r}
#### Use full sf filtered to ensure calculation of running time
full_sf_min <- full_sf_filtered %>%
  st_drop_geometry() %>%
  group_by("time" = cut(timestamp, "1 min")) %>%
  summarise(
    distance = sum(steplength, na.rm = TRUE),
    hightdiff_up = sum(hightdiff_up, na.rm = TRUE),
    hightdiff_down = sum(hightdiff_down, na.rm = TRUE),
    hightdiff_balance = hightdiff_up + hightdiff_down,
    time_eff = sum(timelag, na.rm = TRUE),
    mean_pace = time_eff / distance * 1000 / 60
  ) %>%
  mutate(vertical_direction = ifelse(hightdiff_balance > 2, "up",
                                      ifelse(hightdiff_balance < -2, "down",
                                             "horizontal")))

full_sf_min <- full_sf_min %>%
  filter(time_eff < 100, time_eff > 0, mean_pace < 25)
```

Multimodel Inference for min.model

```{r}
#### ZF: Use moving time (andd)! Sort graphics according to time measured!
min.model <- lm(time_eff/60 ~ 0 + distance + hightdiff_up + hightdiff_down, data=full_sf_min)
options(na.action="na.fail")
allmodels.min <- dredge(min.model)
allmodels.min   # model[1] makes more sence than zf.model!
# Interpretation: Per meter of Distance 0.00461 minutes, per meter up 0.035 minutes
#  per meter down 0.01 minutes (negative because hightdiff_down is negative!).

importance(allmodels.min)

avgmodel.min<-model.avg(get.models(dredge(min.model,rank="AICc"),subset=TRUE))
summary(avgmodel.min) # All predictors are highli significant!

# Komischerweise ist das "drittbeste Modell" einiges genauer als das beste Modell...
distance_param_min <- allmodels.min$distance[1]
up_param_min <- allmodels.min$hightdiff_up[1]
down_param_min <- allmodels.min$hightdiff_down[1]

zf$time_estimated_min <- zf$distance *distance_param_min + zf$hightdiff_up * up_param_min + zf$hightdiff_down * down_param_min

zf %>% 
  dplyr::select(activity_ID, time_measured = time, time_estimated, time_estimated_min, distance, hightdiff_up, hightdiff_down) %>%
  gather(type, value, time_measured, time_estimated_min) %>%
  ggplot(aes(activity_ID, value, col = type)) +
  geom_point() +
  geom_line() +
  theme_bw() +
  labs(x = "\nAktivitäts-ID", y = "Zeitbedarf in min\n")

zf %>% 
  select(activity_ID, time_measured = time, time_estimated_min, distance, hightdiff_up, hightdiff_down) %>%
  gather(type, value, time_measured, time_estimated_min) %>%
  ggplot(aes(distance, value, col = type)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_bw()
# It seems that the model underestimates time requirement for long distances, and overestimates
#  for short distances => Exhaution!

# Show the pace-dependency of the hightdifference up
full_sf_min %>%
  filter(vertical_direction == "up") %>%
  ggplot(aes(hightdiff_up, mean_pace)) +
  geom_point() +
  geom_smooth(span = 1) +
  ylim(4.3,14.5) +
  theme_bw() +
  labs(x = "\nhightdifference up per minute of running time", y = "mean pace per minute of running time\n")

full_sf_min %>%
  filter(vertical_direction == "down") %>%
  ggplot(aes(-hightdiff_down, mean_pace)) +
  geom_point() +
  geom_smooth(span = 1) +
  ylim(4.4,11) +
  xlim(0,38) +
  theme_bw() +
  labs(x = "\nhightdifference down per minute of running time", y = "mean pace per minute of running time\n")

ggplot(full_sf_min, aes(mean_pace, hightdiff_down)) +
  geom_point()

```

## 6.2 validation of the model 


```{r}
valid_time <- 10000 * distance_param_min + 500 * up_param_min + 500 * down_param_min


```

